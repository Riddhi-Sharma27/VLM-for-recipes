# -*- coding: utf-8 -*-
"""AIMS RESEARCH INTERN FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jX9Ek-Xs7GlUW_NYam0zvhL47S_sGhgQ
"""

!pip install transformers accelerate safetensors torch torchvision

!pip install transformers accelerate sentencepiece

from google.colab import files
import zipfile, os
from PIL import Image

uploaded = files.upload()

for fname in uploaded:
    if fname.endswith('.zip'):
        folder_name = os.path.splitext(fname)[0]
        with zipfile.ZipFile(fname, 'r') as zip_ref:
            zip_ref.extractall(folder_name)
        print(f"‚úÖ Extracted to: {folder_name}")

import os
import json
from PIL import Image
import requests
from bs4 import BeautifulSoup

# ==== CONFIG ====
image_folder = "VLM task food/VLM task food"
output_json_path = "dish_metadata.json"
valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')

# ==== Scrape instructions from AllRecipes ====
def get_allrecipes_instructions(dish_name):
    try:
        query = dish_name.replace('_', '+')
        url = f"https://www.allrecipes.com/search?q={query}"
        headers = {"User-Agent": "Mozilla/5.0"}
        search_resp = requests.get(url, headers=headers)
        soup = BeautifulSoup(search_resp.content, "html.parser")

        first_result = soup.select_one("a.card__titleLink")
        if not first_result:
            return ["No instructions found."]

        recipe_url = first_result["href"]
        recipe_resp = requests.get(recipe_url, headers=headers)
        recipe_soup = BeautifulSoup(recipe_resp.content, "html.parser")

        instructions = recipe_soup.select("ul.instructions-section li p")
        steps = [step.get_text(strip=True) for step in instructions]

        return steps if steps else ["No steps found."]
    except Exception as e:
        return [f"Error fetching instructions: {e}"]

# ==== MAIN LOOP ====
metadata_list = []
import time
contents = os.listdir(image_folder)

for fname in contents:
    file_path = os.path.join(image_folder, fname)

    if os.path.isdir(file_path) or not fname.lower().endswith(valid_exts):
        continue

    try:
        image = Image.open(file_path).convert("RGB")

        # Ask user for noisy title instead of using Gemini
        noisy_title = input(f"üé≠ Enter a noisy title for {fname}: ")

        # Get original dish name (without extension) for recipe search
        search_name = os.path.splitext(fname)[0]
        print(f"üîç Searching AllRecipes for: {search_name}")
        instructions = get_allrecipes_instructions(search_name)

        # Ask user for summary
        summary = input(f"üìù Enter summary for {fname}: ")

        metadata_list.append({
            "file_name": fname,
            "noisy_title": noisy_title,
            "instructions": instructions,
            "summary": summary
        })

        print(f"‚úÖ Done: {fname} ‚Üí '{noisy_title}'")

    except Exception as e:
        print(f"‚ùå Error processing {fname}: {e}")
    time.sleep(1)

# ==== SAVE JSON ====
with open(output_json_path, "w", encoding="utf-8") as f:
    json.dump(metadata_list, f, indent=4, ensure_ascii=False)

print(f"\n‚úÖ JSON saved to: {output_json_path}")

"""***LLAVA MODEL***"""

from transformers import AutoProcessor, LlavaForConditionalGeneration
import torch, gc
from PIL import Image
import requests
from transformers import LlavaProcessor

def generate_summary(image_path, noisy_title):
    model_id = "llava-hf/llava-1.5-7b-hf"

    model = LlavaForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
    ).to(0)

    processor = AutoProcessor.from_pretrained(model_id)

    torch.cuda.empty_cache()
    gc.collect()

    image = Image.open(image_path).convert("RGB")

    system_prompt = (
        "You are a helpful cooking assistant. Generate a concise 2‚Äì3 step cooking summary on how to make the dish. Include all important ingredients in the instructions itself. Keep the summary concise. "
        "based on a food image and a noisy or vague title. Use these examples:\n\n"
        "Image: Cinnamon_rolls\n"
        "Noisy title: Snap and Swirl Rolls\n"
        "Summary: Mix warm milk, melted margarine, flour, sugar, yeast, salt, egg, and water into dough; knead and let rest. Roll out dough, spread cinnamon-sugar filling with raisins, roll up, slice, and bake at 375¬∞F for 20 min.\n\n"
        "Image: Cheesy_garlic_bread\n"
        "Noisy title: Savory Bread Melt\n"
        "Summary: Butter bread, add garlic powder, Parmesan, mozzarella. Broil until golden, top with parsley.\n\n"
        "Image: rajma\n"
        "Noisy title: Spiced Bean Lava\n"
        "Summary: Soak kidney beans overnight. Saut√© spices, add tomatoes, pressure cook beans, stir in garam masala, garnish.\n\n"
        "Image: ratatouille\n"
        "Noisy title: Veggie Swirl Stew\n"
        "Summary: Mix tomato paste, onion, garlic, water, olive oil base. Layer vegetables, drizzle oil, season, bake 375¬∞F 45 min.\n\n"
        "Image: naan\n"
        "Noisy title: Yeast Flat\n"
        "Summary: Mix yeast, sugar, warm water; sit 10 min. Add flour, salt, yogurt, ghee; knead, rise 1.5 hrs. Shape, brush ghee, broil 2 min sides.\n\n"
        "Image: strawberry_drink\n"
        "Noisy title: Pink Velvet Pour\n"
        "Summary: Blend strawberries, amaretto, vanilla ice cream, extract, vodka, ice. Pour, top with whipped cream and strawberry.\n\n"
        "Image: fried_rice\n"
        "Noisy title: Golden Grain Toss\n"
        "Summary: Boil carrots briefly, add peas, drain. Stir-fry with garlic, scramble eggs, add rice, toss with soy sauce, sesame oil.\n"
    )

    conversation = [
        {
            "role": "system",
            "content": [{"type": "text", "text": system_prompt}],
        },
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": f"noisy dish title: {noisy_title}"},
                {"type": "text", "text": "Please provide a concise 2‚Äì3 step summary on how to make the dish."},
            ],
        },
    ]

    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)

    inputs = processor(images=image, text=prompt, return_tensors="pt").to(0, torch.float16)

    with torch.no_grad():
        output = model.generate(**inputs, max_new_tokens=100)

    torch.cuda.empty_cache()
    gc.collect()

    response = processor.batch_decode(output[:, inputs["input_ids"].shape[-1]:], skip_special_tokens=True)[0]

    return response

def load_and_resize(path, size=(336, 336)):
    return Image.open(path).convert("RGB").resize(size)

from google.colab import files
import json
from PIL import Image
uploaded = files.upload()

uploaded = files.upload()

uploaded = files.upload()

"""***VIEWING THE TEST DATASET***"""

import json
from IPython.display import display
with open("/content/Test_dataset.json") as f:
    data = json.load(f)
for item in data:
    filename = item["file_name"]
    title = item.get("noisy_title")
    summary = item["summary"]

    print(f"Title: {title}\nSummary: {summary}\n")


    img = Image.open(filename)
    display(img)

import gc
gc.collect()
import gc
import torch

"""***JSON LOOP***"""

import json
with open("/content/Test_dataset.json") as f:
    data = json.load(f)
results = []

for item in data:
    filename = item["file_name"]
    noisy_title = item.get("noisy_title")
    summary = generate_summary(filename,noisy_title)
    print(f"{filename} ‚Üí {summary}")
    results.append({
        "file_name": filename,
        "noisy_title": noisy_title,
        "summary": summary,
    })
    torch.cuda.empty_cache()
    gc.collect()

with open("summary_results.json", "w") as out_f:
    json.dump(results, out_f, indent=2)

"""***CLEARING GPU MEMORY***"""

import torch
import gc
for var in ['model', 'inputs', 'output', 'response', 'processor']:
    try:
        del globals()[var]
    except KeyError:
        pass
gc.collect()
torch.cuda.empty_cache()
torch.cuda.ipc_collect()

import torch
import gc

def clear_gpu_memory():
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.ipc_collect()

clear_gpu_memory()

"""***EVALUATION- Bleu Score***"""

!pip install nltk

import json
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

reference_path = "Test_dataset.json"
generated_path = "summary_results.json"

with open(reference_path, "r") as f:
    reference_json = json.load(f)

with open(generated_path, "r") as f:
    generated_json = json.load(f)

refs = {item["file_name"]: item["summary"] for item in reference_json}
gens = {item["file_name"]: item["summary"] for item in generated_json}

def tokenize(text):
    return text.lower().split()

smooth_fn = SmoothingFunction().method1

bleu_scores = []

for filename in refs:
    ref_summary = refs[filename]
    gen_summary = gens.get(filename)

    if gen_summary is None:
        print(f"{filename}: No generated summary found.")
        continue

    ref_tokens = [tokenize(ref_summary)]
    gen_tokens = tokenize(gen_summary)

    if gen_tokens:
        score = sentence_bleu(ref_tokens, gen_tokens, smoothing_function=smooth_fn)
        print(f"{filename}: BLEU = {score:.4f}")
        bleu_scores.append(score)
    else:
        print(f"{filename}: Generated summary is empty.")

average_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0
print(f"\nAverage BLEU score: {average_bleu:.4f}")